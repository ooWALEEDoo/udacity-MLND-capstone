{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import itertools\n",
    "import math\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from python_speech_features import mfcc, fbank, logfbank\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reciters_paths = glob.glob('./reciters/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths_dictionary = {}\n",
    "test_paths_dictionary = {}\n",
    "\n",
    "for i, j in itertools.groupby(reciters_paths, key=lambda x: x.split('/')[-2]):\n",
    "    files = list(j)\n",
    "    train_paths, test_paths = train_test_split(files, test_size=0.30)\n",
    "    train_paths_dictionary[int(i)-1] = train_paths\n",
    "    test_paths_dictionary[int(i)-1] = test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# training_data = {}\n",
    "# for reciter_id, reciter_path in train_paths_dictionary.items():\n",
    "#     training_data[reciter_id] = []\n",
    "#     for clip_path in random.sample(reciter_path, min(1, len(reciter_path))):\n",
    "#         clip = AudioSegment.from_mp3(clip_path).split_to_mono()[0]\n",
    "#         clip_sample_rate = clip.frame_rate\n",
    "#         nfft = 2 ** math.ceil(np.log2(0.025 * clip_sample_rate))\n",
    "#         clip_sliced = list(clip[::6400])\n",
    "#         print(reciter_id)\n",
    "#         print(clip.channels)\n",
    "#         print(clip_sample_rate)\n",
    "#         samples = random.sample(clip_sliced, min(10, len(clip_sliced)))\n",
    "#         for sample in samples:\n",
    "#             features = mfcc(np.array(sample.get_array_of_samples()), samplerate=clip_sample_rate, nfft=nfft)\n",
    "#             training_data[reciter_id].append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [13:06<00:00, 22.46s/it]\n",
      "100%|██████████| 35/35 [11:08<00:00, 19.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 6s, sys: 2min 35s, total: 27min 42s\n",
      "Wall time: 24min 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_data_and_labels(paths_dictionary):\n",
    "    number_of_labels = len(paths_dictionary)\n",
    "    number_of_segments = 254\n",
    "    number_of_features = 13\n",
    "    x = []\n",
    "    y = []\n",
    "    for reciter_id, reciter_path in tqdm(paths_dictionary.items()):\n",
    "        for clip_path in random.sample(reciter_path, min(10, len(reciter_path))):\n",
    "            clip = AudioSegment.from_mp3(clip_path).split_to_mono()[0]\n",
    "            clip_sample_rate = clip.frame_rate\n",
    "            nfft = 2 ** math.ceil(np.log2(0.025 * clip_sample_rate))\n",
    "            clip_sliced = list(clip[::2560])[:-1] # to avoid the last incomplete slice\n",
    "    #         print(reciter_id)\n",
    "    #         print(clip.channels)\n",
    "    #         print(clip_sample_rate)\n",
    "            samples = random.sample(clip_sliced, min(10, len(clip_sliced)))\n",
    "            for sample in samples:\n",
    "                features = mfcc(np.array(sample.get_array_of_samples()), samplerate=clip_sample_rate, nfft=nfft)\n",
    "                x.append(features[:number_of_segments, :])\n",
    "                y.append(reciter_id)\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = get_data_and_labels(train_paths_dictionary)\n",
    "x_test, y_test = get_data_and_labels(test_paths_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ = x_train.reshape((x_train.shape[0], x_train.shape[1] * x_train.shape[2]))\n",
    "x_test_ = x_test.reshape((x_test.shape[0], x_test.shape[1] * x_test.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a98eab7f4073>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: predict() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# clf = LogisticRegression()\n",
    "# clf.fit(x_train_, y_train)\n",
    "# pred = clf.predict(x_test_)\n",
    "# accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.layers import Input, Dense, LSTM, Dropout, Embedding, Bidirectional, SpatialDropout1D, Flatten, MaxPool1D\n",
    "from keras.layers import Concatenate, Average, Add, GlobalAveragePooling1D, GlobalMaxPooling1D, CuDNNLSTM, CuDNNGRU, GRU\n",
    "from keras.layers import BatchNormalization, GaussianNoise, GaussianDropout, AlphaDropout\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = to_categorical(y_train)\n",
    "y_test_ = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class precision_callback(Callback):\n",
    "    def __init__(self):\n",
    "        super(precision_callback, self).__init__()\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        if not ('val_precision' in self.params['metrics']):\n",
    "            self.params['metrics'].append('val_precision')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        logs['val_precision'] = float('-inf')\n",
    "        if(self.validation_data):\n",
    "            y_pred = self.model.predict(self.validation_data[0], batch_size = self.params['batch_size'])\n",
    "            y_pred = np.array([np.argmax(p) for p in y_pred])\n",
    "            \n",
    "            y_test = self.validation_data[1]\n",
    "            y_test = np.array([np.argmax(p) for p in y_test])\n",
    "            \n",
    "            logs['val_precision'] = precision_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1 = Input(shape=(254, 13, ))\n",
    "x = Flatten()(inp1)\n",
    "# x = SpatialDropout1D(0.1)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(35, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=inp1, outputs=x)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(x_train, to_categorical(y_train), epochs=3, batch_size=1024, verbose=1, \n",
    "          validation_data=(x_test, to_categorical(y_test)), callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound = AudioSegment.from_mp3(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = sound.frame_rate\n",
    "signal = np.array(sound.get_array_of_samples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sound[::5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in sound[::5000]:\n",
    "    print(type(chunk))\n",
    "#     mfcc(np.array(chunk.get_array_of_samples()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
