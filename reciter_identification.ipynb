{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "import glob\n",
    "import random\n",
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from python_speech_features import mfcc, fbank, logfbank\n",
    "from pydub import AudioSegment\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading files' paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reciters_paths = glob.glob('./reciters/*/*')\n",
    "\n",
    "train_paths_dictionary = {}\n",
    "validation_paths_dictionary = {}\n",
    "test_paths_dictionary = {}\n",
    "\n",
    "for i, j in itertools.groupby(reciters_paths, key=lambda x: x.split('/')[-2]):\n",
    "    files = list(j)\n",
    "    train_paths, test_paths = train_test_split(files, test_size=0.30, random_state=13)\n",
    "    test_paths, validation_paths = train_test_split(test_paths, test_size=0.30, random_state=13)\n",
    "    train_paths_dictionary[int(i)] = train_paths\n",
    "    test_paths_dictionary[int(i)] = test_paths\n",
    "    validation_paths_dictionary[int(i)] = validation_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(a=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# def get_data_and_labels(paths_dictionary):\n",
    "#     number_of_labels = len(paths_dictionary)\n",
    "#     number_of_segments = 254\n",
    "#     number_of_features = 13\n",
    "#     x = []\n",
    "#     y = []\n",
    "#     for reciter_id, reciter_path in tqdm(paths_dictionary.items()):\n",
    "#         for clip_path in random.sample(reciter_path, min(10, len(reciter_path))):\n",
    "#             clip = AudioSegment.from_mp3(clip_path).split_to_mono()[0]\n",
    "#             clip_sample_rate = clip.frame_rate\n",
    "#             nfft = 2 ** math.ceil(np.log2(0.025 * clip_sample_rate))\n",
    "#             clip_sliced = list(clip[::5000])[:-1] # to avoid the last incomplete slice\n",
    "#             samples = random.sample(clip_sliced, min(5, len(clip_sliced)))\n",
    "#             for sample in samples:\n",
    "#                 features = mfcc(np.array(sample.get_array_of_samples()), \n",
    "#                                 samplerate=clip_sample_rate, nfft=nfft, numcep=26)\n",
    "#                 x.append(features[:number_of_segments, :])\n",
    "#                 y.append(reciter_id)\n",
    "#     x = np.array(x)\n",
    "#     y = np.array(y)\n",
    "    \n",
    "#     return x, y\n",
    "\n",
    "# x_train, y_train = get_data_and_labels(train_paths_dictionary)\n",
    "# x_test, y_test = get_data_and_labels(test_paths_dictionary)\n",
    "# x_val, y_val = get_data_and_labels(validation_paths_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving MFCC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./features/x_train_26.npy', x_train)\n",
    "# np.save('./features/x_test_26.npy', x_test)\n",
    "# np.save('./features/x_val_26.npy', x_val)\n",
    "# np.save('./features/y_train_26.npy', y_train)\n",
    "# np.save('./features/y_test_26.npy', y_test)\n",
    "# np.save('./features/y_val_26.npy', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('./features/x_train_26.npy')\n",
    "x_test = np.load('./features/x_test_26.npy')\n",
    "x_val = np.load('./features/x_val_26.npy')\n",
    "y_train = np.load('./features/y_train_26.npy')\n",
    "y_test = np.load('./features/y_test_26.npy')\n",
    "y_val = np.load('./features/y_val_26.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# clf = LogisticRegression()\n",
    "# clf.fit(x_train_, y_train)\n",
    "# pred = clf.predict(x_test_)\n",
    "# accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, TensorBoard\n",
    "from keras.layers import Input, Dense, LSTM, Dropout, Embedding, Bidirectional, SpatialDropout1D, Flatten, MaxPool1D\n",
    "from keras.layers import Concatenate, Average, Add, GlobalAveragePooling1D, GlobalMaxPooling1D, CuDNNLSTM, CuDNNGRU, GRU\n",
    "from keras.layers import BatchNormalization, GaussianNoise, GaussianDropout, AlphaDropout\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class accuracy_callback(Callback):\n",
    "    def __init__(self):\n",
    "        super(accuracy_callback, self).__init__()\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        if not ('val_accuracy' in self.params['metrics']):\n",
    "            self.params['metrics'].append('val_accuracy')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        logs['val_accuracy'] = float('-inf')\n",
    "        if(self.validation_data):\n",
    "            y_pred = self.model.predict([self.validation_data[0]], batch_size = self.params['batch_size'])\n",
    "            y_pred = np.array([np.argmax(p) for p in y_pred])\n",
    "            \n",
    "            y_test = self.validation_data[1]\n",
    "            y_test = np.array([np.argmax(p) for p in y_test])\n",
    "            \n",
    "            logs['val_accuracy'] = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "inp = Input(shape=(254, 26))\n",
    "x = SpatialDropout1D(0.05)(inp)\n",
    "x = Bidirectional(CuDNNGRU(512, return_sequences=True, name='bidirectional_gru'))(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(256, activation=\"relu\", name='dense_1')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(50, activation=\"softmax\", name='output')(x)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.0, patience=5, verbose=1, mode='max')\n",
    "checkpoint = ModelCheckpoint('model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "tb = TensorBoard(log_dir='./logs', write_graph=True, write_grads=True, write_images=True)\n",
    "\n",
    "\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, to_categorical(y_train), epochs=50, batch_size=128, verbose=1, \n",
    "          validation_data=(x_val, to_categorical(y_val)), \n",
    "          callbacks=[accuracy_callback(), early_stopping, checkpoint, tb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = load_model('model.h5')\n",
    "pred = model.predict(x_test)\n",
    "pred = [np.argmax(entry) for entry in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, pred)* 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
